<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blog</title>
    <description></description>
    <link>http://www.dosrc.com/mark/</link>
    <atom:link href="http://www.dosrc.com/mark/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Tue, 10 Aug 2021 17:25:15 +0800</pubDate>
    <lastBuildDate>Tue, 10 Aug 2021 17:25:15 +0800</lastBuildDate>
    <generator>Jekyll v4.2.0</generator>
    
      <item>
        <title>Rank Metrics&amp;Loss</title>
        <description>&lt;h2 id=&quot;排序评价&quot;&gt;排序评价&lt;/h2&gt;
&lt;h3 id=&quot;precisionk&quot;&gt;Precision@K&lt;/h3&gt;

\[precision@k=\frac{count_{pos}}{k}\]

&lt;p&gt;其中\(count_{pos}\)为topk中正例个数，是否是正例使用threshold来判别。&lt;/p&gt;

\[\begin{cases}
 &amp;amp; pos, &amp;amp;\text{if} &amp;amp; label &amp;gt;threshold \\ 
 &amp;amp; neg, &amp;amp;\text{if} &amp;amp; label&amp;lt;= threshold
\end{cases}\]

&lt;p&gt;取值范围\([0,1]\)&lt;/p&gt;

&lt;h3 id=&quot;averageprecision&quot;&gt;AveragePrecision&lt;/h3&gt;

\[AveragePrecision = \frac{1}{N}\sum_{k=1}^{N} precision@k\]

&lt;p&gt;取值范围\([0,1]\)&lt;/p&gt;

&lt;h3 id=&quot;meanaverageprecision&quot;&gt;MeanAveragePrecision&lt;/h3&gt;

\[MeanAveragePrecision = \frac{1}{N}\sum_{k\in position_{label=pos}}^{N} precision@k\]

&lt;p&gt;其中\(  position_{label&amp;gt;threshold} \)为所有正例被排序的位置&lt;/p&gt;

&lt;p&gt;含义：分别计算precision@k（k为推荐序列中正例被排序的位置）的平均值。
例如：排序了5个，其中1，3，5为正例，则
MeanAveragePrecision=mean([precision@1,precision@3,precision@5])&lt;/p&gt;

&lt;p&gt;取值范围\([0,1]\)&lt;/p&gt;

&lt;h3 id=&quot;meanreciprocalrank&quot;&gt;MeanReciprocalRank&lt;/h3&gt;

\[MeanReciprocalRank=\frac{1}{k}\]

&lt;p&gt;k为排序中第一个正例位置&lt;/p&gt;

&lt;p&gt;取值范围\((0,1]\)&lt;/p&gt;
&lt;h3 id=&quot;cumulativegain&quot;&gt;CumulativeGain&lt;/h3&gt;

\[CG_{k} = \sum_{i=1}^{k}rel_{i}\]

&lt;p&gt;\(rel_{i}\)是第\( i \)个位置的评分&lt;/p&gt;

&lt;p&gt;取值范围\([0,+\propto)\)&lt;/p&gt;

&lt;p&gt;缺点：前后位置得分未做区分&lt;/p&gt;

&lt;h3 id=&quot;discountedcumulativegain&quot;&gt;DiscountedCumulativeGain&lt;/h3&gt;

\[DCG_{k} = \sum_{i=1}^{k}\frac{2^{rel_{i}}-1}{\log_{2}\left(i+1\right)}\]

&lt;p&gt;\(rel_{i}\)是第\( i \)个位置的评分&lt;/p&gt;

&lt;p&gt;取值范围\([0,+\propto)\)&lt;/p&gt;

&lt;p&gt;缺点：不同算法得分不好做比较&lt;/p&gt;

&lt;h3 id=&quot;normalizeddiscountedcumulativegain&quot;&gt;NormalizedDiscountedCumulativeGain&lt;/h3&gt;

\[nDCG_{k} = \frac{DCG_{k}}{IDCG_{k}}\]

&lt;p&gt;\(IDCG_{k}\)是按评分rank的理想得分，相当于做得分的归一化&lt;/p&gt;

\[IDCG_{k} = \sum_{i=1}^{\left|  REL_{k}\right|}\frac{2^{rel_{i}}-1}{\log_{2}\left(i+1\right)}\]

&lt;h2 id=&quot;排序损失&quot;&gt;排序损失&lt;/h2&gt;
&lt;h3 id=&quot;rankcrossentropyloss&quot;&gt;RankCrossEntropyLoss&lt;/h3&gt;
&lt;p&gt;example：一个正例样本1， 和多个负例样本0 label = [1,0,0,0…]&lt;/p&gt;

\[RankCrossEntropyLoss = CrossEntropy(pred, label)\]

&lt;p&gt;注意：此处必须构造数据为一个正样本1和多个负样本0，这样才满足概率分布的形式。&lt;/p&gt;

&lt;h3 id=&quot;rankhingeloss&quot;&gt;RankHingeLoss&lt;/h3&gt;

\[y = 
\begin{cases}
 &amp;amp; 1, &amp;amp;\text{if} &amp;amp; x_{1}^{\ast} &amp;gt;= x_{2}^{\ast} \\ 
 &amp;amp;-1, &amp;amp;\text{if} &amp;amp; x_{1}^{\ast} &amp;lt; x_{2}^{\ast}
\end{cases} \\
loss(x1,x2,y)=\max(0,−y∗(x1−x2)+margin)\]

&lt;p&gt;这里\(x_{1}^{\ast}, x_{2}^{\ast}\)表示实际的label得分，\(x_{1}, x_{2}\)表示预测得分&lt;/p&gt;

</description>
        <pubDate>Thu, 29 Jul 2021 00:19:00 +0800</pubDate>
        <link>http://www.dosrc.com/mark/ai/2021/07/29/rank-metrics.html</link>
        <guid isPermaLink="true">http://www.dosrc.com/mark/ai/2021/07/29/rank-metrics.html</guid>
        
        <category>AI，NLP，Rank</category>
        
        
        <category>AI</category>
        
      </item>
    
      <item>
        <title>午后小记</title>
        <description>&lt;p&gt;午后，刚醒不久，一束阳光悄悄爬到了我的桌子上，耳机里放着我想去桂林，衣服穿的不多不少，天气不冷不热，工作也不紧不慢，竟是难得的轻松惬意。&lt;/p&gt;

&lt;p&gt;一个人最好活得像夏天，心中永远向着太阳，可以汗流浃背，也可以在阴凉地听虫鸣鸟叫，看大头蚂蚁穿梭在祖祖辈辈耕种过的土地上。&lt;/p&gt;

&lt;p&gt;最后再来一首我被青春撞了一下腰&lt;/p&gt;
</description>
        <pubDate>Wed, 31 Mar 2021 22:06:00 +0800</pubDate>
        <link>http://www.dosrc.com/mark/essay/2021/03/31/sunshine.html</link>
        <guid isPermaLink="true">http://www.dosrc.com/mark/essay/2021/03/31/sunshine.html</guid>
        
        <category>mind</category>
        
        
        <category>Essay</category>
        
      </item>
    
      <item>
        <title>Exploratory Data Analysis</title>
        <description>&lt;h2 id=&quot;基本分析&quot;&gt;基本分析&lt;/h2&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;root_path =r'/home/kesci/input/titanic/'
train = pd.read_csv(root_path + 'train.csv')
test = pd.read_excel(root_path + 'test.csv')
train.info()
train.describe()
train.count() != train.count().max() 看那些值有缺失
train.describe().loc['count']==train.describe().loc['count'].max() # 看那些数值属性值有缺失
train.describe().loc['min']==train.describe().loc['max'] # 查看那些数值属性是固定值
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h2 id=&quot;缺失值填充&quot;&gt;缺失值填充&lt;/h2&gt;
&lt;p&gt;１. 对于Category型数据用众数进行填充&lt;/p&gt;

&lt;p&gt;２. 对于数值型数据用均值/中位数进行填充&lt;/p&gt;

&lt;h2 id=&quot;散碎点&quot;&gt;散碎点&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;线上线下的效果差距却非常的大,这里面很大一部分原因在于,我们在做特征工程的时候,有一些特征在 训练集合上与label有很强的关系,但是却在测试集上却相对弱很多,我们将训练集进行拆分,分为训练集和验证机；用来模拟训练集和测试集的关系，如果在训练集和验证集上我们发现某特征与label的关系相差不大且都有一定的统计特性,我们就将其作为我们的好特征，即使它是弱特征也无所谓，因为即使过拟合也会在训练集和测试集上表现一致。&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sun, 26 Aug 2018 22:30:00 +0800</pubDate>
        <link>http://www.dosrc.com/mark/machine-learning/2018/08/26/exploratory-data-analysis.html</link>
        <guid isPermaLink="true">http://www.dosrc.com/mark/machine-learning/2018/08/26/exploratory-data-analysis.html</guid>
        
        <category>AI</category>
        
        <category>machine-learning</category>
        
        
        <category>Machine-Learning</category>
        
      </item>
    
      <item>
        <title>Learning Deep Structured Semantic Models for Web Search using Clickthrough Data (pdf)</title>
        <description>&lt;embed src=&quot;/mark/assets/pdf/2018-08-11-learning-deep-structured-semantic-models-for-web-search-using-clickthrough-data/2018-08-11-learning-deep-structured-semantic-models-for-web-search-using-clickthrough-data.pdf#page=1&quot; type=&quot;application/pdf&quot; width=&quot;100%&quot; height=&quot;800px&quot; /&gt;

</description>
        <pubDate>Sun, 12 Aug 2018 02:20:00 +0800</pubDate>
        <link>http://www.dosrc.com/mark/paper/2018/08/12/learning-deep-structured-semantic-models-for-web-search-using-clickthrough-data.html</link>
        <guid isPermaLink="true">http://www.dosrc.com/mark/paper/2018/08/12/learning-deep-structured-semantic-models-for-web-search-using-clickthrough-data.html</guid>
        
        <category>2014</category>
        
        
        <category>Paper</category>
        
      </item>
    
      <item>
        <title>Neural Networks and Physical Systems with Emergent Collective Computational Abilities (pdf)</title>
        <description>&lt;embed src=&quot;/mark/assets/pdf/2018-07-26-neural-networks-and-physical-systems-with-emergent-collective-computational-abilities/2018-07-26-neural-networks-and-physical-systems-with-emergent-collective-computational-abilities.pdf#page=1&quot; type=&quot;application/pdf&quot; width=&quot;100%&quot; height=&quot;800px&quot; /&gt;

</description>
        <pubDate>Thu, 26 Jul 2018 23:10:00 +0800</pubDate>
        <link>http://www.dosrc.com/mark/paper/2018/07/26/neural-networks-and-physical-systems-with-emergent-collective-computational-abilities.html</link>
        <guid isPermaLink="true">http://www.dosrc.com/mark/paper/2018/07/26/neural-networks-and-physical-systems-with-emergent-collective-computational-abilities.html</guid>
        
        <category>2014</category>
        
        
        <category>Paper</category>
        
      </item>
    
      <item>
        <title>Word2Vec Introduce</title>
        <description>&lt;h2 id=&quot;背景&quot;&gt;背景&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;one hot编码缺点&lt;/strong&gt;：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;编码没有将语义融入到词的表示当中&lt;/li&gt;
  &lt;li&gt;维数爆炸&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;word embedding&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;如何将语义融入到词的表示当中? Harris于1954年提出的分布假说（distributional hypothesis）为这一设想提供了理论基础：上下文相似的词，其语义也相似。而基于基于分布假说的词表示方法，根据建模的不同，主要可以分为三类：基于矩阵的分布表示、基于聚类的分布表示和基于神经网络的分布表示。而word embedding一般来说就是一种基于神经网络的分布表示。&lt;/p&gt;
</description>
        <pubDate>Wed, 23 May 2018 21:30:00 +0800</pubDate>
        <link>http://www.dosrc.com/mark/nlp/2018/05/23/word2vec-introduce.html</link>
        <guid isPermaLink="true">http://www.dosrc.com/mark/nlp/2018/05/23/word2vec-introduce.html</guid>
        
        <category>AI</category>
        
        <category>NLP</category>
        
        
        <category>NLP</category>
        
      </item>
    
      <item>
        <title>Neural Turing Machines (pdf)</title>
        <description>&lt;embed src=&quot;/mark/assets/pdf/2018-05-23-neural-turing-machines/2018-05-23-neural-turing-machines.pdf#page=1&quot; type=&quot;application/pdf&quot; width=&quot;100%&quot; height=&quot;800px&quot; /&gt;

</description>
        <pubDate>Wed, 23 May 2018 21:30:00 +0800</pubDate>
        <link>http://www.dosrc.com/mark/paper/2018/05/23/neural-turing-machines.html</link>
        <guid isPermaLink="true">http://www.dosrc.com/mark/paper/2018/05/23/neural-turing-machines.html</guid>
        
        <category>2014</category>
        
        
        <category>Paper</category>
        
      </item>
    
      <item>
        <title>Machine Learning And Its Application In Image Processing (pdf)</title>
        <description>&lt;embed src=&quot;/mark/assets/pdf/2017-06-29-machine-learning-and-its-application-in-image-processing/2017-06-29-machine-learning-and-its-application-in-image-processing.pdf#page=1&quot; type=&quot;application/pdf&quot; width=&quot;100%&quot; height=&quot;800px&quot; /&gt;

</description>
        <pubDate>Wed, 23 May 2018 21:30:00 +0800</pubDate>
        <link>http://www.dosrc.com/mark/ai/2018/05/23/machine-learning-and-its-application-in-image-processing.html</link>
        <guid isPermaLink="true">http://www.dosrc.com/mark/ai/2018/05/23/machine-learning-and-its-application-in-image-processing.html</guid>
        
        <category>AI</category>
        
        <category>image-processing</category>
        
        
        <category>AI</category>
        
      </item>
    
      <item>
        <title>Ruby On Rails</title>
        <description>&lt;h2 id=&quot;安装&quot;&gt;安装&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;安装ruby&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;安装sqlite3&lt;/p&gt;

    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; sudo apt-get install sqlite3
 sudo apt-get install libsqlite3-dev
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;安装rails&lt;/p&gt;

    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; gem install rails
 rails --version
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;使用rails创建博客&lt;/p&gt;

    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; rails new blog
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;启动web服务器&lt;/p&gt;

    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; cd blog
 bin/rails server
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;错误及处理&quot;&gt;错误及处理&lt;/h2&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/var/lib/gems/2.3.0/gems/bundler-1.16.1/lib/bundler/runtime.rb:84:in `rescue in block (2 levels) in require': There was an error while trying to load the gem 'uglifier'. (Bundler::GemRequireError)
Gem Load Error is: Could not find a JavaScript runtime. See https://github.com/rails/execjs for a list of available runtimes.
Backtrace for gem load error is:
/var/lib/gems/2.3.0/gems/execjs-2.7.0/lib/execjs/runtimes.rb:58:in `autodetect'
/var/lib/gems/2.3.0/gems/execjs-2.7.0/lib/execjs.rb:5:in `&amp;lt;module:ExecJS&amp;gt;'
/var/lib/gems/2.3.0/gems/execjs-2.7.0/lib/execjs.rb:4:in `&amp;lt;top (required)&amp;gt;'
/var/lib/gems/2.3.0/gems/uglifier-4.1.1/lib/uglifier.rb:5:in `require'
/var/lib/gems/2.3.0/gems/uglifier-4.1.1/lib/uglifier.rb:5:in `&amp;lt;top (required)&amp;gt;'
/var/lib/gems/2.3.0/gems/bundler-1.16.1/lib/bundler/runtime.rb:81:in `require'
/var/lib/gems/2.3.0/gems/bundler-1.16.1/lib/bundler/runtime.rb:81:in `block (2 levels) in require'
/var/lib/gems/2.3.0/gems/bundler-1.16.1/lib/bundler/runtime.rb:76:in `each'
/var/lib/gems/2.3.0/gems/bundler-1.16.1/lib/bundler/runtime.rb:76:in `block in require'
/var/lib/gems/2.3.0/gems/bundler-1.16.1/lib/bundler/runtime.rb:65:in `each'
/var/lib/gems/2.3.0/gems/bundler-1.16.1/lib/bundler/runtime.rb:65:in `require'
/var/lib/gems/2.3.0/gems/bundler-1.16.1/lib/bundler.rb:114:in `require'
/home/ez/blog/config/application.rb:7:in `&amp;lt;top (required)&amp;gt;'
/var/lib/gems/2.3.0/gems/railties-5.1.4/lib/rails/commands/server/server_command.rb:133:in `require'
...
...

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;原因：没有JavaScript runtime
解决方法：sudo apt-get install nodejs
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
</description>
        <pubDate>Sat, 23 Dec 2017 20:30:00 +0800</pubDate>
        <link>http://www.dosrc.com/mark/web/2017/12/23/begin-ruby-on-rails.html</link>
        <guid isPermaLink="true">http://www.dosrc.com/mark/web/2017/12/23/begin-ruby-on-rails.html</guid>
        
        <category>web</category>
        
        <category>ruby</category>
        
        <category>ruby-on-rails</category>
        
        
        <category>Web</category>
        
      </item>
    
      <item>
        <title>Playing Atari with Deep Reinforcement Learning (pdf)</title>
        <description>&lt;embed src=&quot;/mark/assets/pdf/2017-12-23-playing-atari-with-deep-reinforcement-learning/2017-12-23-playing-atari-with-deep-reinforcement-learning.pdf&quot; type=&quot;application/pdf&quot; width=&quot;100%&quot; height=&quot;800px&quot; /&gt;

</description>
        <pubDate>Sat, 23 Dec 2017 20:30:00 +0800</pubDate>
        <link>http://www.dosrc.com/mark/paper/2017/12/23/playing-atari-with-deep-reinforcement-learning.html</link>
        <guid isPermaLink="true">http://www.dosrc.com/mark/paper/2017/12/23/playing-atari-with-deep-reinforcement-learning.html</guid>
        
        <category>nips</category>
        
        <category>2013</category>
        
        
        <category>Paper</category>
        
      </item>
    
  </channel>
</rss>
