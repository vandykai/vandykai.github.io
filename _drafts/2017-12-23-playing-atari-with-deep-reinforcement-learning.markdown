---

layout: post
title:  Playing Atari with Deep Reinforcement Learning
date:   2017-12-23 12:30:00
categories: [Paper]
tags: [nips, 2013]

---
## 作者信息
## 简介
直接从传感器传来的裸数据中学习控制智能体的策略一直以来都是强化学习的一个巨大挑战。
深度学习的突破性进展使得从裸数据中提取特征成为可能，这为计算机视觉，语音识别带来重大突破，它们（计算机视觉，语音识别）使用了一系列神经网络的架构，包括卷积神经网络，多层感知机，限制玻尔兹曼机，循环神经网络，既有使用监督学习，也有使用非监督学习。那么我们自然会问这一技术是否能为强化学习带来些什么。

然而从深度学习的视角来看，强化学习结合深度学习面临着一些困难。

1. 大部分成功的深度学习应用可能需要大量手工标注数据一样（这些深度学习算法从训练数据的标签中学习），同样强化学习的奖励信号也有着稀疏，噪声，延迟的问题（这些强化学习算法从奖励信号中学习），有时候奖励信号可能会延迟上千个迭代步之后才到来，这就使得学习输入和目标输出之间的联系变得异常困难。

2. 大部分的深度学习算法假设数据样本之间是独立的，且分布是固定不变的，然而强化学习中的数据大都是相关的，而且数据的分布会随着学习的进行而改变。

本文证明了卷积神经网络可以克服这些困难从视频裸数据中学习到控制策略。该神经网络使用Q学习算法的一个变种进行训练，使用梯度下降算法更新权重。为了缓和数据相关和分布不固定的问题，我们使用了经验回放机制（experience replay mechanism），即通过多次随机采样之前的状态转移，来平滑训练分布的变化。

## 相关知识
马尔可夫决策过程

Atari 2600：雅达利（Atari）在1977年10月发行的一款游戏机，在当年风行一时，成为电子游戏第二世代的代表主机。当中经典的游戏包括Adventure、碰碰弹子台、爆破彗星和Pac-Man等。早期采用1.19MHz MOS 8位元6507处理器，后期升级到2MHz 6502处理器。支持160 X 192分辨率屏幕，最高128色，当然，还有主机上有128 bytes的RAM和6Kb的ROM内存。游戏盘每个售价25美元，容量4KB，不过通过技术手段可以使卡带达到10K的容量。

由于观察只观察当前画面几乎不可能完全理解当前所处的环境，所以我们定义状态为$$s _{t} = x _{1},a _{1},x _{2},\dots,a _{t-1},x _{t}$$

[1]: https://arxiv.org/abs/1312.5602
[2]: https://arxiv.org/pdf/1312.5602.pdf

